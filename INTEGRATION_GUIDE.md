# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ò–ò –≤ FastAPI –ø—Ä–æ–µ–∫—Ç

## üéØ –û–±–∑–æ—Ä

–≠—Ç–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ò–ò —Å–µ—Ä–≤–∏—Å—ã –∏ –º–æ–¥–µ–ª–∏ –≤ –≤–∞—à FastAPI –≤–µ–±-—Å–∞–π—Ç.

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ `main.py`:

```python
@app.post("/api/process-text")
async def process_text(text: str = Form(...)):
    # –ó–∞–º–µ–Ω–∏—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É –Ω–∞ –≤–∞—à—É –ò–ò –ª–æ–≥–∏–∫—É:
    # result = your_ai_model.process(text)
    
    # –ü—Ä–∏–º–µ—Ä –ø—Ä–æ—Å—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:
    processed_text = f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {text.upper()}"
    
    return {
        "input": text,
        "output": processed_text,
        "status": "success"
    }
```

### 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥–æ—Ç–æ–≤—ã—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∞–π–ª `ai_integration_example.py` –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ò–ò —Å–µ—Ä–≤–∏—Å–æ–≤.

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
pip install openai
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞
1. –ü–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á –Ω–∞ [platform.openai.com](https://platform.openai.com)
2. –î–æ–±–∞–≤—å—Ç–µ –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
```bash
export OPENAI_API_KEY="your-api-key-here"
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ main.py
```python
import openai
import os

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
openai.api_key = os.getenv("OPENAI_API_KEY")

@app.post("/api/openai/chat")
async def chat_with_gpt(text: str = Form(...)):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": text}],
            max_tokens=1000
        )
        
        return {
            "input": text,
            "output": response.choices[0].message.content,
            "model": "gpt-3.5-turbo",
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

## ü§ó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Hugging Face

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
pip install transformers torch
```

### –õ–æ–∫–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
```python
from transformers import pipeline

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
classifier = pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-sentiment-latest")

@app.post("/api/hf/sentiment")
async def analyze_sentiment(text: str = Form(...)):
    try:
        result = classifier(text)
        return {
            "text": text,
            "sentiment": result[0]["label"],
            "confidence": result[0]["score"],
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Hugging Face API
```python
import aiohttp
import os

async def analyze_sentiment_api(text: str):
    headers = {
        "Authorization": f"Bearer {os.getenv('HF_API_KEY')}",
        "Content-Type": "application/json"
    }
    
    data = {"inputs": text}
    
    async with aiohttp.ClientSession() as session:
        async with session.post(
            "https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment-latest",
            headers=headers,
            json=data
        ) as response:
            return await response.json()
```

## üß† –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ scikit-learn
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import pickle

# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
with open('model.pkl', 'rb') as f:
    model = pickle.load(f)

vectorizer = TfidfVectorizer()

@app.post("/api/local/classify")
async def classify_text(text: str = Form(...)):
    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    text_vectorized = vectorizer.transform([text])
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = model.predict(text_vectorized)[0]
    probability = model.predict_proba(text_vectorized).max()
    
    return {
        "text": text,
        "prediction": prediction,
        "confidence": probability,
        "status": "success"
    }
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ spaCy
```python
import spacy

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
nlp = spacy.load("en_core_web_sm")

@app.post("/api/spacy/analyze")
async def analyze_text(text: str = Form(...)):
    doc = nlp(text)
    
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    tokens = [token.text for token in doc]
    
    return {
        "text": text,
        "entities": entities,
        "tokens": tokens,
        "status": "success"
    }
```

## üìä –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Google Cloud AI

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```bash
pip install google-cloud-language
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞
1. –°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ–µ–∫—Ç –≤ Google Cloud Console
2. –í–∫–ª—é—á–∏—Ç–µ Natural Language API
3. –°–æ–∑–¥–∞–π—Ç–µ —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç –∏ —Å–∫–∞—á–∞–π—Ç–µ JSON –∫–ª—é—á
4. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è:
```bash
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/service-account-key.json"
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
```python
from google.cloud import language_v1

client = language_v1.LanguageServiceClient()

@app.post("/api/google/analyze")
async def analyze_text_google(text: str = Form(...)):
    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)
    
    # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
    sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment
    
    # –ê–Ω–∞–ª–∏–∑ —Å—É—â–Ω–æ—Å—Ç–µ–π
    entities = client.analyze_entities(request={'document': document}).entities
    
    return {
        "text": text,
        "sentiment": {
            "score": sentiment.score,
            "magnitude": sentiment.magnitude
        },
        "entities": [{"name": e.name, "type": e.type_.name} for e in entities],
        "status": "success"
    }
```

## üé® –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ ai_demo.html

```html
<!-- –î–æ–±–∞–≤—å—Ç–µ –Ω–æ–≤—É—é —Å–µ–∫—Ü–∏—é –¥–ª—è –ò–ò —Ñ—É–Ω–∫—Ü–∏–π -->
<div class="row mb-4">
    <div class="col-lg-6">
        <div class="card border-0 shadow-sm">
            <div class="card-header bg-info text-white">
                <h5 class="mb-0">
                    <i class="fas fa-brain me-2"></i>–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
                </h5>
            </div>
            <div class="card-body">
                <form id="sentimentForm">
                    <div class="mb-3">
                        <label for="sentimentText" class="form-label">–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:</label>
                        <textarea class="form-control" id="sentimentText" rows="3"></textarea>
                    </div>
                    <button type="submit" class="btn btn-info">
                        <i class="fas fa-chart-line me-2"></i>–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
                    </button>
                </form>
            </div>
        </div>
    </div>
    <div class="col-lg-6">
        <div class="card border-0 shadow-sm">
            <div class="card-header bg-warning text-dark">
                <h5 class="mb-0">
                    <i class="fas fa-lightbulb me-2"></i>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
                </h5>
            </div>
            <div class="card-body">
                <div id="sentimentResult">
                    <p class="text-muted text-center">–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å</p>
                </div>
            </div>
        </div>
    </div>
</div>
```

### JavaScript –¥–ª—è –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π

```javascript
// –î–æ–±–∞–≤—å—Ç–µ –≤ ai_demo.html –≤ —Å–µ–∫—Ü–∏—é scripts

// –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
document.getElementById('sentimentForm').addEventListener('submit', async function(e) {
    e.preventDefault();
    const text = document.getElementById('sentimentText').value;
    
    if (!text.trim()) {
        alert('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞');
        return;
    }
    
    showLoading();
    
    try {
        const formData = new FormData();
        formData.append('text', text);
        
        const response = await fetch('/api/hf/sentiment', {
            method: 'POST',
            body: formData
        });
        
        const result = await response.json();
        
        document.getElementById('sentimentResult').innerHTML = `
            <div class="alert alert-success">
                <h6>–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:</h6>
                <p><strong>–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:</strong> ${result.sentiment}</p>
                <p><strong>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</strong> ${(result.confidence * 100).toFixed(1)}%</p>
            </div>
        `;
    } catch (error) {
        document.getElementById('sentimentResult').innerHTML = `
            <div class="alert alert-danger">
                <h6>–û—à–∏–±–∫–∞:</h6>
                <p>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ</p>
            </div>
        `;
    } finally {
        hideLoading();
    }
});
```

## üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
```python
from pydantic import BaseModel, validator

class TextInput(BaseModel):
    text: str
    
    @validator('text')
    def validate_text(cls, v):
        if len(v.strip()) == 0:
            raise ValueError('–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º')
        if len(v) > 10000:
            raise ValueError('–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π')
        return v.strip()

@app.post("/api/secure/process")
async def secure_process_text(input_data: TextInput):
    # –í–∞—à–∞ –ò–ò –ª–æ–≥–∏–∫–∞ –∑–¥–µ—Å—å
    return {"result": "processed"}
```

### –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–æ–≤
```python
from fastapi import UploadFile, File

@app.post("/api/upload-secure")
async def upload_secure_file(file: UploadFile = File(...)):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞ (10MB)
    if file.size > 10 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
    allowed_types = [".txt", ".pdf", ".doc", ".docx"]
    if not any(file.filename.endswith(ext) for ext in allowed_types):
        raise HTTPException(status_code=400, detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞")
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import logging
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.post("/api/ai/process")
async def process_with_logging(text: str = Form(...)):
    start_time = datetime.now()
    
    try:
        # –í–∞—à–∞ –ò–ò –ª–æ–≥–∏–∫–∞
        result = await your_ai_function(text)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.info(f"AI processing completed in {processing_time}s for text: {text[:50]}...")
        
        return result
    except Exception as e:
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏
        logger.error(f"AI processing failed: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal server error")
```

## üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ

### Docker —Å –ò–ò –º–æ–¥–µ–ª—è–º–∏
```dockerfile
FROM python:3.9-slim

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY requirements.txt .
RUN pip install -r requirements.txt

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
COPY . .

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
RUN mkdir -p uploads models

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env`:
```env
OPENAI_API_KEY=your-openai-key
HF_API_KEY=your-huggingface-key
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
MODEL_PATH=/app/models
MAX_FILE_SIZE=10485760
```

## üéØ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ß–∞—Ç-–±–æ—Ç —Å –ø–∞–º—è—Ç—å—é
```python
from collections import defaultdict

# –ü—Ä–æ—Å—Ç–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
conversation_history = defaultdict(list)

@app.post("/api/chat")
async def chat_with_memory(
    message: str = Form(...),
    user_id: str = Form(...)
):
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    conversation_history[user_id].append({"role": "user", "content": message})
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π)
    if len(conversation_history[user_id]) > 10:
        conversation_history[user_id] = conversation_history[user_id][-10:]
    
    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ò–ò
    context = "\n".join([msg["content"] for msg in conversation_history[user_id]])
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ –ò–ò
    response = await your_ai_model.process(context)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
    conversation_history[user_id].append({"role": "assistant", "content": response})
    
    return {"response": response, "history_length": len(conversation_history[user_id])}
```

### –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
```python
import PyPDF2
import docx

@app.post("/api/analyze-document")
async def analyze_document(file: UploadFile = File(...)):
    content = ""
    
    if file.filename.endswith('.pdf'):
        # –ß—Ç–µ–Ω–∏–µ PDF
        pdf_reader = PyPDF2.PdfReader(file.file)
        for page in pdf_reader.pages:
            content += page.extract_text()
    elif file.filename.endswith('.docx'):
        # –ß—Ç–µ–Ω–∏–µ DOCX
        doc = docx.Document(file.file)
        for paragraph in doc.paragraphs:
            content += paragraph.text + "\n"
    
    # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –ò–ò
    analysis = await your_ai_model.analyze_document(content)
    
    return {
        "filename": file.filename,
        "content_length": len(content),
        "analysis": analysis
    }
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [FastAPI –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://fastapi.tiangolo.com/)
- [Hugging Face –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è](https://huggingface.co/docs)

---

**–£–¥–∞—á–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏! üöÄ** 